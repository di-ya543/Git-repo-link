Model Chosen: CodeT5 (Hugging Face)

Link: https://huggingface.co/Salesforce/codet5-base

Summary:

Transformer-based model designed for source code understanding and generation.

Pre-trained on multiple programming languages, including Python.

Capable of learning both syntax and semantics, making it effective for detecting logical misconceptions.



Strengths

Strong performance in code summarization, bug detection, and code-to-text tasks.

Large open-source community support.

Available in different sizes (small, base, large), making it flexible for performance constraints.
